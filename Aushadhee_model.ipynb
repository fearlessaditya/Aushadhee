{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "760322a6-3558-4131-8206-a09c2c4113e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9393a7-c566-40f5-a3c5-b3857cff9ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 30000 files [07:12, 69.34 files/s]\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"plant_data2\\Input_dataset\"\n",
    "output = \"plant_data2\\output\"\n",
    "splitfolders.ratio(input_folder,output,seed=42,ratio=(0.8,0.1,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797c6ece-66c3-4f6d-b7a2-6d144661712d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scipy) (1.24.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc938ac3-01b9-457e-b5bf-b6257a001702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ec45e9-892f-4c6f-9433-61db6d9baf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = (244,244)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56029dfd-65f0-413f-9aca-08ee40acd5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = r\"plant_data2\\output\\train\" \n",
    "valid_data_dir = r\"plant_data2\\output\\val\"\n",
    "test_data_dir = r\"plant_data2\\output\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff7bcdb6-020b-427c-83f7-8a7688883d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4800 images belonging to 30 classes.\n",
      "Found 2400 images belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.8)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset= 'training') # set as training data\n",
    "valid_generator = train_datagen.flow_from_directory(\n",
    "    valid_data_dir,   # set as validation data\n",
    "    target_size=(img_height, img_width), \n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset= 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1186ad9-d397-4d9f-921d-88db6508a15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 images belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = train_datagen.flow_from_directory(\n",
    "test_data_dir, #same directory as training data \n",
    "target_size=(img_height, img_width),\n",
    "batch_size=1,\n",
    "class_mode='categorical',\n",
    "subset='validation') #set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32225999-d673-4197-8ae5-af956bbde731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 244, 244, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = test_generator.next()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd3dc3b9-fc9d-428e-9bef-3e5801daf037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "314359e6-b2b1-4b7e-ad0f-eeeb4e7cb7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6c2d4a8-2279-4966-8a72-c2c83bdf6aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aloevera', 'banana', 'bilimbi', 'cantaloupe', 'cassava', 'coconut', 'corn', 'cucumber', 'curcuma', 'eggplant', 'galangal', 'ginger', 'guava', 'kale', 'longbeans', 'mango', 'melon', 'orange', 'paddy', 'papaya', 'peper chili', 'pineapple', 'pomelo', 'shallot', 'soybeans', 'spinach', 'sweet potatoes', 'tobacco', 'waterapple', 'watermelon']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = r\"C:\\Users\\ACER\\plant_data2\\output\\val\"\n",
    "name = os.listdir(path)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b4fa91d-72a4-47be-a887-001ce26b7b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "[[1.8350976e-03 1.4053230e-02 9.7287875e-01 3.1238244e-05 2.8130942e-04\n",
      "  1.4685604e-04 2.6185336e-04 1.8835381e-03 1.5724685e-04 3.0967416e-04\n",
      "  5.2910711e-04 5.1937730e-04 3.6254714e-04 4.8146176e-04 1.7916637e-04\n",
      "  2.2040003e-04 8.1413200e-05 4.4211044e-04 3.6150447e-04 1.1598034e-03\n",
      "  2.8589042e-04 5.8905798e-04 4.0905617e-04 2.6358842e-04 4.0048265e-04\n",
      "  5.1862520e-05 8.8732537e-05 5.6894580e-05 1.3724389e-03 3.0635079e-04]] \n",
      "Index: 3\n",
      "Species:  bilimbi\n"
     ]
    }
   ],
   "source": [
    "#base_model = load_model(r'C:\\Users\\ACER\\plant_data2\\Saved_model\\resnet50_aushadhee2.h5')\n",
    "#x = base_model.output\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "#x = Dense(1074, activation='relu')(x)\n",
    "#predictions1 = Dense (train_generator.num_classes, activation='softmax' )(x) \n",
    "#model = Model(inputs=base_model.input, outputs=predictions1)\n",
    "#for layer in base_model.layers: \n",
    "#    layer.trainable = False\n",
    "model = load_model(r'C:\\Users\\ACER\\plant_data2\\Saved_model\\resnet50_aushadhee2.h5')\n",
    "\n",
    "model.compile(loss='catagorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "img = cv2.imread(r\"bilimbi325.jpg\")\n",
    "img1 = cv2.resize(img,(244,244))\n",
    "img2 = np.reshape(img1,[1,244,244,3])\n",
    "\n",
    "classes = model.predict(img2)\n",
    "l1 = classes.tolist()\n",
    "loca = max(l1[0])\n",
    "indx = (l1[0].index(loca)+1)\n",
    "#print(next(i for i, x in enumerate(classes) if x == loca))\n",
    "#for i in range(1,classes):\n",
    "#    print(\"x:\",x)\n",
    "  #  if x == loca:\n",
    "    #    print(\"i:\",i)\n",
    "#print(\"loca:\" , loca)\n",
    "print(classes,\"\\nIndex:\",indx)\n",
    "for j in name:\n",
    "    if indx == (name.index(j)+1):\n",
    "        print(\"Species: \",j)\n",
    "#print(\"Accuracy:\" , loca*100,\"%\")\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "#model.fit(train_generator,epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef984055-8054-4f26-8c19-25146525c667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baee0477-23bd-4fdb-81cb-c25380de8841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 - 160s - loss: 1.5580 - accuracy: 0.6442 - 160s/epoch - 133ms/step\n",
      "\n",
      "Test accuracy: 0.6441666483879089\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print(\"\\nTest accuracy:\",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75a3ba7d-271d-43f7-a0f2-633b381a5692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 - 315s - loss: 1.4508 - accuracy: 0.6650 - 315s/epoch - 8s/step\n",
      "\n",
      "Test accuracy: 0.6650000214576721\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(valid_generator, verbose=2)\n",
    "print(\"\\nTest accuracy:\",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd09acfc-abfd-4aca-9638-699bd5eaf7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 - 197s - loss: 1.3311 - accuracy: 0.7179 - 197s/epoch - 5s/step\n",
      "\n",
      "Test accuracy: 0.7179166674613953\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(valid_generator, verbose=2)\n",
    "print(\"\\nTest accuracy:\",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d359caa6-a18a-4104-8d25-12f8cd7a569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 - 181s - loss: 1.3642 - accuracy: 0.7163 - 181s/epoch - 5s/step\n",
      "\n",
      "Test accuracy: 0.7162500023841858\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(valid_generator, verbose=2)\n",
    "print(\"\\nTest accuracy:\",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbbb3a6a-be73-4fbe-8a77-3e9500c2f73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 - 292s - loss: 1.4927 - accuracy: 0.6850 - 292s/epoch - 122ms/step\n",
      "\n",
      "Test accuracy: 0.6850000023841858\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print(\"\\nTest accuracy:\",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59f1a39f-ccdb-4ffb-be9c-cdc0ff287f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'C:\\Users\\ACER\\plant_data2\\Saved_model\\resnet50_aushadhee2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72cc6bd2-a8d7-43a4-af00-f856be286aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "75/75 [==============================] - 365s 5s/step - loss: 1.8347 - accuracy: 0.8954\n",
      "Epoch 2/5\n",
      "75/75 [==============================] - 365s 5s/step - loss: 0.2836 - accuracy: 0.9229\n",
      "Epoch 3/5\n",
      "75/75 [==============================] - 356s 5s/step - loss: 0.2493 - accuracy: 0.9281\n",
      "Epoch 4/5\n",
      "75/75 [==============================] - 356s 5s/step - loss: 0.2204 - accuracy: 0.9348\n",
      "Epoch 5/5\n",
      "75/75 [==============================] - 358s 5s/step - loss: 0.2426 - accuracy: 0.9283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x274bc4f6590>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = load_model(r'C:\\Users\\ACER\\plant_data2\\Saved_model\\resnet50_aushadhee2.h5')\n",
    "x = base_model.output\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1074, activation='relu')(x)\n",
    "predictions = Dense (train_generator.num_classes, activation='softmax' )(x) \n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in base_model.layers: \n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(train_generator,epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68edae2b-c897-49cd-a7dc-f02675f15610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 - 307s - loss: 1.7139 - accuracy: 0.6758 - 307s/epoch - 128ms/step\n",
      "\n",
      "Test accuracy: 0.6758333444595337\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print(\"\\nTest accuracy:\",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c30d0c0d-07dc-458c-826e-57e7fda65624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 - 179s - loss: 1.4840 - accuracy: 0.7117 - 179s/epoch - 5s/step\n",
      "\n",
      "Test accuracy: 0.7116666436195374\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(valid_generator, verbose=2)\n",
    "print(\"\\nTest accuracy:\",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861ab72a-cb37-448f-95ed-47ed6a92b30a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
